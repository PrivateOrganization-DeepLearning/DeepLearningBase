{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[] Type: <class 'torch.nn.parameter.Parameter'>,  size: torch.Size([64, 3, 11, 11])\n",
      "[] Type: <class 'torch.nn.parameter.Parameter'>,  size: torch.Size([64])\n",
      "[] Type: <class 'torch.nn.parameter.Parameter'>,  size: torch.Size([192, 64, 5, 5])\n",
      "[] Type: <class 'torch.nn.parameter.Parameter'>,  size: torch.Size([192])\n",
      "[] Type: <class 'torch.nn.parameter.Parameter'>,  size: torch.Size([384, 192, 3, 3])\n",
      "[] Type: <class 'torch.nn.parameter.Parameter'>,  size: torch.Size([384])\n",
      "[] Type: <class 'torch.nn.parameter.Parameter'>,  size: torch.Size([256, 384, 3, 3])\n",
      "[] Type: <class 'torch.nn.parameter.Parameter'>,  size: torch.Size([256])\n",
      "[] Type: <class 'torch.nn.parameter.Parameter'>,  size: torch.Size([256, 256, 3, 3])\n",
      "[] Type: <class 'torch.nn.parameter.Parameter'>,  size: torch.Size([256])\n",
      "[] Type: <class 'torch.nn.parameter.Parameter'>,  size: torch.Size([10, 256])\n",
      "[] Type: <class 'torch.nn.parameter.Parameter'>,  size: torch.Size([10])\n",
      "[1,   200] loss: 2.303\n",
      "[1,   400] loss: 2.302\n",
      "[1,   600] loss: 2.301\n",
      "[2,   200] loss: 2.291\n",
      "[2,   400] loss: 2.256\n",
      "[2,   600] loss: 2.164\n",
      "[3,   200] loss: 2.065\n",
      "[3,   400] loss: 2.023\n",
      "[3,   600] loss: 1.974\n",
      "[4,   200] loss: 1.927\n",
      "[4,   400] loss: 1.913\n",
      "[4,   600] loss: 1.883\n",
      "[5,   200] loss: 1.826\n",
      "[5,   400] loss: 1.832\n",
      "[5,   600] loss: 1.798\n",
      "[6,   200] loss: 1.760\n",
      "[6,   400] loss: 1.724\n",
      "[6,   600] loss: 1.721\n",
      "[7,   200] loss: 1.679\n",
      "[7,   400] loss: 1.659\n",
      "[7,   600] loss: 1.646\n",
      "[8,   200] loss: 1.612\n",
      "[8,   400] loss: 1.603\n",
      "[8,   600] loss: 1.571\n",
      "[9,   200] loss: 1.547\n",
      "[9,   400] loss: 1.544\n",
      "[9,   600] loss: 1.535\n",
      "[10,   200] loss: 1.505\n",
      "[10,   400] loss: 1.501\n",
      "[10,   600] loss: 1.489\n",
      "Accuracy of plane : 44 %\n",
      "Accuracy of   car : 63 %\n",
      "Accuracy of  bird : 21 %\n",
      "Accuracy of   cat : 17 %\n",
      "Accuracy of  deer : 18 %\n",
      "Accuracy of   dog : 43 %\n",
      "Accuracy of  frog : 63 %\n",
      "Accuracy of horse : 57 %\n",
      "Accuracy of  ship : 50 %\n",
      "Accuracy of truck : 66 %\n",
      "[] Save network \n",
      "[] Weight size:  (256,)\n",
      "[] F size:  torch.Size([16, 256, 9, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pulpan92\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type AlexNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\pulpan92\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\skimage\\transform\\_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "C:\\Users\\pulpan92\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\skimage\\transform\\_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Label: cat\n",
      "[] Predict: cat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Label: deer\n",
      "[] Predict: frog\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Label: car\n",
      "[] Predict: car\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Label: frog\n",
      "[] Predict: deer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Label: cat\n",
      "[] Predict: frog\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Label: dog\n",
      "[] Predict: dog\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Label: truck\n",
      "[] Predict: car\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Label: ship\n",
      "[] Predict: car\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Label: car\n",
      "[] Predict: truck\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Label: horse\n",
      "[] Predict: horse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Label: deer\n",
      "[] Predict: deer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Label: car\n",
      "[] Predict: car\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Label: cat\n",
      "[] Predict: cat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Label: plane\n",
      "[] Predict: ship\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Label: truck\n",
      "[] Predict: car\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Label: bird\n",
      "[] Predict: deer\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import skimage.transform\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, class_num):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.feature_network = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size = (11, 11), stride = 4, padding = 5),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.classifier_network = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 1 * 1, class_num)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        avg = nn.AvgPool2d(9)\n",
    "        \n",
    "        f1 = self.feature_network(x)\n",
    "#         print('[]f1 size: ', f1.size())\n",
    "        f2 = avg(f1)\n",
    "#         print('[] f2 size: ', f2.size())\n",
    "        f3 = f2.view(-1, 256 * 1 * 1)\n",
    "        result = self.classifier_network(f3)\n",
    "        \n",
    "        return result, f1\n",
    "    \n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "#     print('[] npimg shape: ', npimg.shape)\n",
    "    t = np.transpose(npimg, (1, 2, 0))\n",
    "#     print('[] shape: ', t.shape)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "#     print('[] npimg shape: ', npimg.shape)\n",
    "\n",
    "\n",
    "def main():\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    AN = AlexNet(len(classes))\n",
    "    \n",
    "    transform = transforms.Compose([transforms.Resize(224), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root = './data', train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root = './data', train=False, download = True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size = 64, shuffle = True, num_workers=2)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(AN.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    AN.to(device)\n",
    "    \n",
    "    param = list(AN.parameters())\n",
    "    for p in param:\n",
    "        print(\"[] Type: {},  size: {}\".format(type(p), p.size()))\n",
    "    \n",
    "    for epoch in range(0, 10):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "#             print('[] Input size: ', inputs.size())\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs, F = AN.forward(inputs)\n",
    "#             print('[] outputs shape: ', outputs.size())\n",
    "#             print('[] labels shape: ', labels.size())\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 200 == 199:\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "                running_loss = 0.0\n",
    "                \n",
    "                \n",
    "    class_correct = list(0 for i in range(10))\n",
    "    class_total = list(0 for i in range(10))\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs, F = AN.forward(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                c = (predicted == labels).squeeze()\n",
    "    \n",
    "                for i in range(4):\n",
    "                    label = labels[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "    \n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "    \n",
    "    param = list(AN.parameters())\n",
    "    W = param[-2].cpu().data.numpy()\n",
    "\n",
    "    print('[] Weight size: ', W[1].shape)\n",
    "    print('[] F size: ', F.size())\n",
    "    \n",
    "    t = F[0].reshape([256, 81])\n",
    "    \n",
    "    # F -> before AvgPooling\n",
    "    for i in range(0, 16):\n",
    "        pred_val = predicted[i].item()\n",
    "        label_val = labels[i].item()\n",
    "        \n",
    "        # Make CAM picture \n",
    "        CAM_img = W[pred_val].dot(F[i].reshape([256, 81]))\n",
    "        CAM_img = CAM_img.reshape(9, 9) \n",
    "        \n",
    "        CAM_img -= CAM_img.min()\n",
    "        CAM_img /= CAM_img.max()\n",
    "        \n",
    "        imshow(images[i].cpu())\n",
    "        \n",
    "        CAM = skimage.transform.resize(CAM_img, [224, 224])\n",
    "        plt.imshow(CAM, alpha = 0.5)\n",
    "        plt.show()\n",
    "        print('[] Label: {}\\n[] Predict: {}'.format(classes[label_val], classes[pred_val]))\n",
    "                    \n",
    "#     print('[] F: ' ,F.size())\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
